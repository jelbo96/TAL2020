{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Ejercicio: Análisis de sentimientos en español\n",
    "\n",
    "Análisis de sentimientos de los tweets en español sobre aerolineas: Analizar cómo los viajeros expresaron sus sentimientos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926419989107798016</th>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trabajar en #Ryanair como #TMA: https://t.co/r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri Nov 03 12:05:12 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934854385577943041</th>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Iberia @FIONAFERRER Cuando gusten en Cancún s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Nov 26 18:40:28 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945318406441635840</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sabiais que @Iberia te trata muy bien en santi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Dec 25 15:40:45 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927540721296568320</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NUNCA NUNCA NUNCA pidáis el café de Ryanair.\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Nov 06 14:18:35 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947965901332197376</th>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@cris_tortu @dakar @Iberia @Mitsubishi_ES @BFG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Jan 01 23:00:57 +0000 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buenos Aires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   airline_sentiment  is_reply  reply_count  retweet_count  \\\n",
       "tweet_id                                                                     \n",
       "926419989107798016           neutral     False            0              0   \n",
       "934854385577943041           neutral      True            0              0   \n",
       "945318406441635840          negative     False            0              0   \n",
       "927540721296568320          negative     False            0              0   \n",
       "947965901332197376          positive      True            0              0   \n",
       "\n",
       "                                                                 text  \\\n",
       "tweet_id                                                                \n",
       "926419989107798016  Trabajar en #Ryanair como #TMA: https://t.co/r...   \n",
       "934854385577943041  @Iberia @FIONAFERRER Cuando gusten en Cancún s...   \n",
       "945318406441635840  Sabiais que @Iberia te trata muy bien en santi...   \n",
       "927540721296568320  NUNCA NUNCA NUNCA pidáis el café de Ryanair.\\n...   \n",
       "947965901332197376  @cris_tortu @dakar @Iberia @Mitsubishi_ES @BFG...   \n",
       "\n",
       "                   tweet_coord                   tweet_created tweet_location  \\\n",
       "tweet_id                                                                        \n",
       "926419989107798016         NaN  Fri Nov 03 12:05:12 +0000 2017            NaN   \n",
       "934854385577943041         NaN  Sun Nov 26 18:40:28 +0000 2017            NaN   \n",
       "945318406441635840         NaN  Mon Dec 25 15:40:45 +0000 2017            NaN   \n",
       "927540721296568320         NaN  Mon Nov 06 14:18:35 +0000 2017            NaN   \n",
       "947965901332197376         NaN  Mon Jan 01 23:00:57 +0000 2018            NaN   \n",
       "\n",
       "                                 user_timezone  \n",
       "tweet_id                                        \n",
       "926419989107798016                      Madrid  \n",
       "934854385577943041                 Mexico City  \n",
       "945318406441635840                      Madrid  \n",
       "927540721296568320  Pacific Time (US & Canada)  \n",
       "947965901332197376                Buenos Aires  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_public.csv', encoding='utf-8', index_col='tweet_id')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    3769\n",
       "neutral     2609\n",
       "positive    1489\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feedback Value count\n",
    "df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamientos y representación vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=\"\"\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = Spanish()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function spacy_tokenizer at 0x7fa96eccc488>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partición de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text'] # the features we want to analyze\n",
    "ylabels = df['airline_sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación del modelo de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jelbo/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x7fa96eccc488>)),\n",
       "                ('regression-ML', LogisticRegression())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('preprocessing', bow_vector),\n",
    "                 ('regression-ML', modelLR)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'negative' ... 'negative' 'neutral' 'neutral']\n",
      "Logistic Regression Accuracy: 0.5849008642602949\n",
      "Logistic Regression Precision: 0.5762942034540115\n",
      "Logistic Regression Recall: 0.5849008642602949\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted, average='weighted'))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1408  384  105]\n",
      " [ 483  636  173]\n",
      " [ 175  313  257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.74      0.71      1897\n",
      "     neutral       0.48      0.49      0.48      1292\n",
      "    positive       0.48      0.34      0.40       745\n",
      "\n",
      "    accuracy                           0.58      3934\n",
      "   macro avg       0.55      0.53      0.53      3934\n",
      "weighted avg       0.58      0.58      0.58      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predicted)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNMostInformative(vectorizer, model, N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(model.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    topClass3 = coefs_with_fns[0:0]   #Esos valores determinan el neutral\n",
    "    #Tengo que definir que rango val1:val2 es neutral\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)\n",
    "    print(\"Class 3 best: \")\n",
    "    for feat in topClass3:\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 best: \n",
      "(-0.9569317849042004, 'felicidades')\n",
      "(-0.9498548765582929, 'gracias')\n",
      "(-0.890321412161182, 'foto')\n",
      "(-0.8493104605352927, 'reconocerá')\n",
      "(-0.8242900485947552, 'holaargentina')\n",
      "(-0.8205271783703655, 'feliz')\n",
      "(-0.7710217714504983, 'necesita')\n",
      "(-0.7387460254054002, 'quiero')\n",
      "(-0.7202436831537699, 'mira')\n",
      "(-0.6833973489516223, 'reconocer')\n",
      "(-0.682701798761811, 'encanta')\n",
      "(-0.6787189503724856, 'salido')\n",
      "(-0.6693770810064339, 't')\n",
      "(-0.6660728521272005, 'mejor')\n",
      "(-0.6490279107430258, '@fjlopezm')\n",
      "(-0.6461405210519526, 'b')\n",
      "(-0.6355517755981822, 'barato')\n",
      "(-0.6340962002410947, 'desconvocan')\n",
      "(-0.6329973385349146, 'sindicatos')\n",
      "(-0.6276880908885452, 'buen')\n",
      "Class 2 best: \n",
      "(1.3450082499148317, 'retraso')\n",
      "(1.0509972991338727, 'vergüenza')\n",
      "(1.0113276206561146, '@supermanlopezn')\n",
      "(0.9822566191217572, 'normal')\n",
      "(0.9723167631232462, 'ninguna')\n",
      "(0.8807567127164401, 'puto')\n",
      "(0.8799672448994099, 'retrasados')\n",
      "(0.8787598804663005, 'peor')\n",
      "(0.868624193271852, 'caro')\n",
      "(0.8663845249849166, 'mierda')\n",
      "(0.8433904583638939, 'esperando')\n",
      "(0.8232020538303857, 'cancelaciones')\n",
      "(0.8203577456209682, 'esperar')\n",
      "(0.8198731869973113, 'ojo')\n",
      "(0.8109567761172622, 'sin')\n",
      "(0.7542985424662593, 'https://t.co/xj0zfyh8zk')\n",
      "(0.7542985424662593, 'https://t.co/j7xzvm54gn')\n",
      "(0.7542985424662593, 'https://t.co/gy6bg8fp8f')\n",
      "(0.7542985424662593, 'https://t.co/ebidmuqcva')\n",
      "(0.7542985424662593, 'https://t.co/c4cfwdwmm9')\n",
      "Class 3 best: \n"
     ]
    }
   ],
   "source": [
    "printNMostInformative(bow_vector, modelLR, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
